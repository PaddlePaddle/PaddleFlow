apiVersion: v1
kind: Pod
metadata:
  name: default-name
  namespace: default
spec:
  containers:
    - image: nginx
      imagePullPolicy: IfNotPresent
      name: job-default-name
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  priorityClassName: normal
  restartPolicy: Never
  schedulerName: volcano
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
# single-job
---
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: sparkName
  namespace: default
spec:
  driver:
    serviceAccount: spark
    terminationGracePeriodSeconds: 30
  executor:
    terminationGracePeriodSeconds: 30
  image:
  imagePullPolicy: IfNotPresent
  mainApplicationFile:
  mainClass:
  mode: cluster
  restartPolicy:
    onSubmissionFailureRetries: 3
    onSubmissionFailureRetryInterval: 5
    type: Never
  sparkConf:
    spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: "2"
  sparkVersion: 3.0.0
  type: Scala
  batchSchedulerOptions:
    queue:
    priorityClass:
# spark-job
---
apiVersion: batch.paddlepaddle.org/v1
kind: PaddleJob
metadata:
  name: default-name
spec:
  withGloo: 1
  intranet: PodIP
  cleanPodPolicy: OnCompletion
  worker:
    replicas: 2
    restartPolicy: Never
    template:
      spec:
        containers:
          - name: paddle
            image: registry.baidubce.com/paddle-operator/demo-wide-and-deep:v1
        terminationGracePeriodSeconds: 30
  ps:
    replicas: 2
    restartPolicy: Never
    template:
      spec:
        containers:
          - name: paddle
            image: registry.baidubce.com/paddle-operator/demo-wide-and-deep:v1
        terminationGracePeriodSeconds: 30
# paddle-ps-job
---
apiVersion: batch.paddlepaddle.org/v1
kind: PaddleJob
metadata:
  name: default-name
spec:
  cleanPodPolicy: Never
  worker:
    replicas: 2
    template:
      spec:
        containers:
          - name: worker-name
            image: registry.baidubce.com/paddle-operator/demo-resnet:v1
        terminationGracePeriodSeconds: 30
# paddle-collective-job
---
apiVersion: "kubeflow.org/v1"
kind: PaddleJob
metadata:
  name: paddle-simple-cpu
  namespace: kubeflow
spec:
  paddleReplicaSpecs:
    Worker:
      replicas: 2
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: paddle
              image: registry.baidubce.com/paddlepaddle/paddle:2.4.0rc0-cpu
              command:
                - python
              args:
                - "-m"
                - paddle.distributed.launch
                - "run_check"
              ports:
                - containerPort: 37777
                  name: master
              imagePullPolicy: Always
# PaddleJob-kubeflow.org/v1-collective
---
apiVersion: "kubeflow.org/v1"
kind: "PyTorchJob"
metadata:
  name: "pytorch-dist-sendrecv"
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: pytorch
              command:
                - /bin/sh
                - -c
                - sleep 10
              image: paddleflow/pytorch-dist-sendrecv-test:1.12.0
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: pytorch
              command:
                - /bin/sh
                - -c
                - sleep 10
              image: paddleflow/pytorch-dist-sendrecv-test:1.12.0
# pytorch-ps-job
---
apiVersion: "kubeflow.org/v1"
kind: "TFJob"
metadata:
  name: "tf-mnist-dist"
spec:
  tfReplicaSpecs:
    PS:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: tensorflow
              image: tf-mnist-dist:1.2
              command:
                - "python"
                - "/var/tf_dist_mnist/dist_mnist.py"
                - "--num_gpus=0"
                # faster trainning
                - "--train_steps=1"
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        spec:
          containers:
            - name: tensorflow
              image: tf-mnist-dist:1.2
              command:
                - "python"
                - "/var/tf_dist_mnist/dist_mnist.py"
                - "--num_gpus=0"
                - "--train_steps=1"
# tensorflow-ps-job
---
apiVersion: ray.io/v1alpha1
kind: RayJob
metadata:
  name: rayjob-sample
spec:
  entrypoint: sleep 60
  shutdownAfterJobFinishes: true
  rayClusterSpec:
    rayVersion: '2.0.0'
    enableInTreeAutoscaling: true
    headGroupSpec:
      serviceType: ClusterIP
      replicas: 1
      rayStartParams:
        node-ip-address: $MY_POD_IP
        block: 'true'
      template:
        metadata:
          labels:
            rayCluster: raycluster-heterogeneous
            rayNodeType: head
            groupName: headgroup
          annotations:
            key: value
        spec:
          containers:
            - name: ray-head
              image: rayproject/ray:2.0.0
              env:
                - name: MY_POD_IP
                  valueFrom:
                    fieldRef:
                      fieldPath: status.podIP
    workerGroupSpecs:
      - replicas: 1
        minReplicas: 1
        maxReplicas: 5
        groupName: small-group
        rayStartParams:
          node-ip-address: $MY_POD_IP
          block: 'true'
        template:
          metadata:
            labels:
              key: value
            annotations:
              key: value
          spec:
            initContainers:
              - name: init-myservice
                image: busybox:1
                command: [ 'sh', '-c', "until nslookup $RAY_IP.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done" ]
            containers:
              - name: machine-learning
                image: rayproject/ray:2.0.0
                env:
                  - name: RAY_DISABLE_DOCKER_CPU_WARNING
                    value: "1"
                  - name: TYPE
                    value: "worker"
                  - name: CPU_REQUEST
                    valueFrom:
                      resourceFieldRef:
                        containerName: machine-learning
                        resource: requests.cpu
                  - name: CPU_LIMITS
                    valueFrom:
                      resourceFieldRef:
                        containerName: machine-learning
                        resource: limits.cpu
                  - name: MEMORY_LIMITS
                    valueFrom:
                      resourceFieldRef:
                        containerName: machine-learning
                        resource: limits.memory
                  - name: MEMORY_REQUESTS
                    valueFrom:
                      resourceFieldRef:
                        containerName: machine-learning
                        resource: requests.memory
                  - name: MY_POD_NAME
                    valueFrom:
                      fieldRef:
                        fieldPath: metadata.name
                  - name: MY_POD_IP
                    valueFrom:
                      fieldRef:
                        fieldPath: status.podIP
                ports:
                  - containerPort: 80
                    name: client
                lifecycle:
                  preStop:
                    exec:
                      command: [ "/bin/sh","-c","ray stop" ]
# ray-job
---
apiVersion: kubeflow.org/v1
kind: MPIJob
metadata:
  name: tensorflow-mnist
spec:
  slotsPerWorker: 1
  runPolicy:
    cleanPodPolicy: Running
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          containers:
            - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
              name: mpi
              command:
                - mpirun
              args:
                - -np
                - "2"
                - --allow-run-as-root
                - -bind-to
                - none
                - -map-by
                - slot
                - -x
                - LD_LIBRARY_PATH
                - -x
                - PATH
                - -mca
                - pml
                - ob1
                - -mca
                - btl
                - ^openib
                - python
                - /examples/tensorflow2_mnist.py
              resources:
                limits:
                  cpu: 1
                  memory: 2Gi
    Worker:
      replicas: 2
      template:
        spec:
          containers:
            - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
              name: mpi
              resources:
                limits:
                  cpu: 2
                  memory: 4Gi
# mpi-job
---
