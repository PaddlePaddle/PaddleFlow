---
apiVersion: v1
kind: Namespace
metadata:
 name: volcano-system
---
apiVersion: v1
kind: Namespace
metadata:
 name: paddleflow
---
---
# Source: pfchart/charts/paddleflow-server/templates/ServiceAccount-paddleflow-server.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: paddleflow-server
  namespace: 'paddleflow'
---
# Source: pfchart/charts/pfs-csi-plugin/templates/ServiceAccount-csi-node-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: csi-node-sa
  namespace: 'paddleflow'
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/ServiceAccount-pfs-csi-provisioner.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: pfs-csi-provisioner
  namespace: 'paddleflow'
---
# Source: pfchart/charts/volcano-admission/templates/ServiceAccount-volcano-admission.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: volcano-admission
  namespace: 'paddleflow'
---
# Source: pfchart/charts/volcano-controller/templates/ServiceAccount-volcano-controllers.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: volcano-controllers
  namespace: 'paddleflow'
---
# Source: pfchart/charts/volcano-scheduler/templates/ServiceAccount-volcano-scheduler.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  creationTimestamp: null
  name: volcano-scheduler
  namespace: 'paddleflow'
---
# Source: pfchart/charts/paddleflow-server/templates/paddleflow-server-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'paddleflow-server'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'paddleflow-server'
        chart: 'paddleflow-server-0.10.57-rq5yqh'
        helm.sh/chart: 'paddleflow-server-0.10.57-rq5yqh'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'paddleflow-server'
data: {}
---
# Source: pfchart/charts/pfs-csi-plugin/templates/pfs-csi-plugin-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'pfs-csi-plugin'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'pfs-csi-plugin'
        chart: 'pfs-csi-plugin-0.0.79-rq5znw'
        helm.sh/chart: 'pfs-csi-plugin-0.0.79-rq5znw'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'pfs-csi-plugin'
data: {}
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/pfs-csi-provisioner-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'pfs-csi-provisioner'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'pfs-csi-provisioner'
        chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
        helm.sh/chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'pfs-csi-provisioner'
data: {}
---
# Source: pfchart/charts/volcano-admission-init/templates/volcano-admission-init-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'volcano-admission-init'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-admission-init'
        chart: 'volcano-admission-init-0.0.8-rq5yzc'
        helm.sh/chart: 'volcano-admission-init-0.0.8-rq5yzc'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-admission-init'
data: {}
---
# Source: pfchart/charts/volcano-admission/templates/volcano-admission-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'volcano-admission'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-admission'
        chart: 'volcano-admission-0.0.21-rq5ysr'
        helm.sh/chart: 'volcano-admission-0.0.21-rq5ysr'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-admission'
data: {}
---
# Source: pfchart/charts/volcano-controller/templates/volcano-controller-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'volcano-controller'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-controller'
        chart: 'volcano-controller-0.0.11-rq5yy7'
        helm.sh/chart: 'volcano-controller-0.0.11-rq5yy7'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-controller'
data: {}
---
# Source: pfchart/charts/volcano-scheduler/templates/volcano-scheduler-secret.yaml
kind: Secret
apiVersion: v1
metadata:
    labels:
        app: 'volcano-scheduler'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-scheduler'
        chart: 'volcano-scheduler-0.0.23-rq5ywm'
        helm.sh/chart: 'volcano-scheduler-0.0.23-rq5ywm'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-scheduler'
data: {}
---
# Source: pfchart/charts/paddleflow-server/templates/paddleflow-server-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'paddleflow-server'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'paddleflow-server'
        chart: 'paddleflow-server-0.10.57-rq5yqh'
        helm.sh/chart: 'paddleflow-server-0.10.57-rq5yqh'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'paddleflow-server'
data:
    default_pv.yaml: |4-
          kind: PersistentVolume
          metadata:
            name: pfs-$(pfs.fs.id)-$(namespace)-pv
            annotations:
              pv.kubernetes.io/provisioned-by: paddleflowstorage
          spec:
            accessModes:
              - ReadWriteMany
            persistentVolumeReclaimPolicy: Delete
            storageClassName: paddleflowstorage
            capacity:
              storage: 400Gi
            csi:
              driver: paddleflowstorage
              fsType: ext4
              volumeAttributes:
                pfs.fs.id: $(pfs.fs.id)
                pfs.server: $(pfs.server)
              volumeHandle: pfs-$(pfs.fs.id)-$(namespace)-pv
    default_pvc.yaml: |4-
          kind: PersistentVolumeClaim
          metadata:
            name: pfs-$(pfs.fs.id)-pvc
            namespace: $(namespace)
          spec:
            accessModes:
              - ReadWriteMany
            resources:
              requests:
                storage: 100Gi
            storageClassName: paddleflowstorage
            volumeMode: Filesystem
            volumeName: pfs-$(pfs.fs.id)-$(namespace)-pv
    job_template.yaml: |
        apiVersion: v1
        kind: Pod
        metadata:
          name: default-name
          namespace: default
        spec:
          containers:
            - image: nginx
              imagePullPolicy: IfNotPresent
              name: job-default-name
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          enableServiceLinks: true
          priorityClassName: normal
          restartPolicy: Never
          schedulerName: volcano
          securityContext: {}
          serviceAccount: default
          serviceAccountName: default
          terminationGracePeriodSeconds: 30
        # single-job
        ---
        apiVersion: sparkoperator.k8s.io/v1beta2
        kind: SparkApplication
        metadata:
          name: sparkName
          namespace: default
        spec:
          driver:
            serviceAccount: spark
            terminationGracePeriodSeconds: 30
          executor:
            terminationGracePeriodSeconds: 30
          image:
          imagePullPolicy: IfNotPresent
          mainApplicationFile:
          mainClass:
          mode: cluster
          restartPolicy:
            onSubmissionFailureRetries: 3
            onSubmissionFailureRetryInterval: 5
            type: Never
          sparkConf:
            spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: "2"
          sparkVersion: 3.0.0
          type: Scala
          batchSchedulerOptions:
            queue:
            priorityClass:
        # spark-job
        ---
        apiVersion: batch.paddlepaddle.org/v1
        kind: PaddleJob
        metadata:
          name: default-name
        spec:
          withGloo: 1
          intranet: PodIP
          cleanPodPolicy: OnCompletion
          worker:
            replicas: 2
            template:
              spec:
                containers:
                  - name: paddle
                    image: registry.baidubce.com/paddle-operator/demo-wide-and-deep:v1
                terminationGracePeriodSeconds: 30
                restartPolicy: Never
          ps:
            replicas: 2
            template:
              spec:
                containers:
                  - name: paddle
                    image: registry.baidubce.com/paddle-operator/demo-wide-and-deep:v1
                terminationGracePeriodSeconds: 30
                restartPolicy: Never
        # paddle-ps-job
        ---
        apiVersion: batch.paddlepaddle.org/v1
        kind: PaddleJob
        metadata:
          name: default-name
        spec:
          cleanPodPolicy: Never
          worker:
            replicas: 2
            template:
              spec:
                containers:
                  - name: worker-name
                    image: registry.baidubce.com/paddle-operator/demo-resnet:v1
                terminationGracePeriodSeconds: 30
                restartPolicy: Never
        # paddle-collective-job
        ---
        apiVersion: "kubeflow.org/v1"
        kind: "PyTorchJob"
        metadata:
          name: "pytorch-dist-sendrecv"
        spec:
          pytorchReplicaSpecs:
            Master:
              replicas: 1
              restartPolicy: Never
              template:
                spec:
                  containers:
                    - name: pytorch
                      command:
                        - /bin/sh
                        - -c
                        - sleep 10
                      image: paddleflow/pytorch-dist-sendrecv-test:1.12.0
            Worker:
              replicas: 1
              restartPolicy: Never
              template:
                spec:
                  containers:
                    - name: pytorch
                      command:
                        - /bin/sh
                        - -c
                        - sleep 10
                      image: paddleflow/pytorch-dist-sendrecv-test:1.12.0
        # pytorch-ps-job
        ---
        apiVersion: "kubeflow.org/v1"
        kind: "TFJob"
        metadata:
          name: "tf-mnist-dist"
        spec:
          tfReplicaSpecs:
            PS:
              replicas: 1
              restartPolicy: Never
              template:
                spec:
                  containers:
                    - name: tensorflow
                      image: tf-mnist-dist:1.2
                      command:
                        - "python"
                        - "/var/tf_dist_mnist/dist_mnist.py"
                        - "--num_gpus=0"
                        # faster trainning
                        - "--train_steps=1"
            Worker:
              replicas: 1
              restartPolicy: Never
              template:
                spec:
                  containers:
                    - name: tensorflow
                      image: tf-mnist-dist:1.2
                      command:
                        - "python"
                        - "/var/tf_dist_mnist/dist_mnist.py"
                        - "--num_gpus=0"
                        - "--train_steps=1"
        # tensorflow-ps-job
        ---
        apiVersion: ray.io/v1alpha1
        kind: RayJob
        metadata:
          name: rayjob-sample
        spec:
          entrypoint: sleep 60
          shutdownAfterJobFinishes: true
          rayClusterSpec:
            rayVersion: '2.0.0'
            enableInTreeAutoscaling: true
            headGroupSpec:
              serviceType: ClusterIP
              replicas: 1
              rayStartParams:
                node-ip-address: $MY_POD_IP
                block: 'true'
              template:
                metadata:
                  labels:
                    rayCluster: raycluster-heterogeneous
                    rayNodeType: head
                    groupName: headgroup
                  annotations:
                    key: value
                spec:
                  containers:
                    - name: ray-head
                      image: rayproject/ray:2.0.0
                      env:
                        - name: MY_POD_IP
                          valueFrom:
                            fieldRef:
                              fieldPath: status.podIP
            workerGroupSpecs:
              - replicas: 1
                minReplicas: 1
                maxReplicas: 5
                groupName: small-group
                rayStartParams:
                  node-ip-address: $MY_POD_IP
                  block: 'true'
                template:
                  metadata:
                    labels:
                      key: value
                    annotations:
                      key: value
                  spec:
                    initContainers:
                      - name: init-myservice
                        image: busybox:1
                        command: [ 'sh', '-c', "until nslookup $RAY_IP.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done" ]
                    containers:
                      - name: machine-learning
                        image: rayproject/ray:2.0.0
                        env:
                          - name: RAY_DISABLE_DOCKER_CPU_WARNING
                            value: "1"
                          - name: TYPE
                            value: "worker"
                          - name: CPU_REQUEST
                            valueFrom:
                              resourceFieldRef:
                                containerName: machine-learning
                                resource: requests.cpu
                          - name: CPU_LIMITS
                            valueFrom:
                              resourceFieldRef:
                                containerName: machine-learning
                                resource: limits.cpu
                          - name: MEMORY_LIMITS
                            valueFrom:
                              resourceFieldRef:
                                containerName: machine-learning
                                resource: limits.memory
                          - name: MEMORY_REQUESTS
                            valueFrom:
                              resourceFieldRef:
                                containerName: machine-learning
                                resource: requests.memory
                          - name: MY_POD_NAME
                            valueFrom:
                              fieldRef:
                                fieldPath: metadata.name
                          - name: MY_POD_IP
                            valueFrom:
                              fieldRef:
                                fieldPath: status.podIP
                        ports:
                          - containerPort: 80
                            name: client
                        lifecycle:
                          preStop:
                            exec:
                              command: [ "/bin/sh","-c","ray stop" ]
        # ray-job
        ---
        apiVersion: kubeflow.org/v1
        kind: MPIJob
        metadata:
          name: tensorflow-mnist
        spec:
          slotsPerWorker: 1
          runPolicy:
            cleanPodPolicy: Running
          mpiReplicaSpecs:
            Launcher:
              replicas: 1
              template:
                spec:
                  containers:
                    - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
                      name: mpi
                      command:
                        - mpirun
                      args:
                        - -np
                        - "2"
                        - --allow-run-as-root
                        - -bind-to
                        - none
                        - -map-by
                        - slot
                        - -x
                        - LD_LIBRARY_PATH
                        - -x
                        - PATH
                        - -mca
                        - pml
                        - ob1
                        - -mca
                        - btl
                        - ^openib
                        - python
                        - /examples/tensorflow2_mnist.py
                      resources:
                        limits:
                          cpu: 1
                          memory: 2Gi
            Worker:
              replicas: 2
              template:
                spec:
                  containers:
                    - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
                      name: mpi
                      resources:
                        limits:
                          cpu: 2
                          memory: 4Gi
        # mpi-job
        ---
    paddleserver.yaml: |
        database:
          driver: sqlite
          host: mysql-standalone
          port: 3306
          user: root
          password: Paddle@2022
          database: paddleflow
        monitor:
          server: "http://127.0.0.1:8395"
        log:
          dir: ./
          filePrefix: log
          level: INFO
          maxKeepDays: 7
          maxFileNum: 7
          maxFileSizeInMB: 100
          isCompress: true
        traceLog:
          dir: ./
          filePrefix: trace-log
          level: INFO
          maxKeepDays: 7
          maxFileNum: 7
          maxFileSizeInMB: 100
          isCompress: true
          timeout: 2h
          maxCacheSize: 10000
          syncInterval: 30s
          deleteInterval: 10s
        apiServer:
          host: paddleflow-server
          port: 8999
          tokenExpirationHour: -1
        fs:
          defaultPVPath: "./config/fs/default_pv.yaml"
          defaultPVCPath: "./config/fs/default_pvc.yaml"
          servicePort: 8999
        job:
          reclaim:
            isCleanJob: true
            isSkipCleanFailedJob: false
            succeededJobTTLSeconds: 3600
            failedJobTTLSeconds: 36000
          schedulerName: volcano
          clusterSyncPeriod: 30
          defaultJobYamlDir: "./config/server/default/job"
          defaultJobYamlPath: "./config/server/default/job/job_template.yaml"
          isSingleCluster: true
        pipeline: pipeline
        imageRepository:
          server: ""
          namespace: ""
          username: ""
          password: ""
          concurrency: 10
          removeLocalImage: true
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/pfs-csi-plugin/templates/pfs-csi-plugin-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'pfs-csi-plugin'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'pfs-csi-plugin'
        chart: 'pfs-csi-plugin-0.0.79-rq5znw'
        helm.sh/chart: 'pfs-csi-plugin-0.0.79-rq5znw'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'pfs-csi-plugin'
data:
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/pfs-csi-provisioner-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'pfs-csi-provisioner'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'pfs-csi-provisioner'
        chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
        helm.sh/chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'pfs-csi-provisioner'
data:
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/volcano-admission-init/templates/volcano-admission-init-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'volcano-admission-init'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-admission-init'
        chart: 'volcano-admission-init-0.0.8-rq5yzc'
        helm.sh/chart: 'volcano-admission-init-0.0.8-rq5yzc'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-admission-init'
data:
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/volcano-admission/templates/volcano-admission-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'volcano-admission'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-admission'
        chart: 'volcano-admission-0.0.21-rq5ysr'
        helm.sh/chart: 'volcano-admission-0.0.21-rq5ysr'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-admission'
data:
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/volcano-controller/templates/volcano-controller-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'volcano-controller'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-controller'
        chart: 'volcano-controller-0.0.11-rq5yy7'
        helm.sh/chart: 'volcano-controller-0.0.11-rq5yy7'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-controller'
data:
    telegraf.conf: |4
        [global_tags]
binaryData: {}
---
# Source: pfchart/charts/volcano-scheduler/templates/volcano-scheduler-configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
    labels:
        app: 'volcano-scheduler'
        app.kubernetes.io/instance: 'paddleflow'
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/name: 'volcano-scheduler'
        chart: 'volcano-scheduler-0.0.23-rq5ywm'
        helm.sh/chart: 'volcano-scheduler-0.0.23-rq5ywm'
        heritage: 'Helm'
        release: 'paddleflow'
    name: 'volcano-scheduler'
data:
    telegraf.conf: |4
        [global_tags]
    volcano-scheduler-pf.conf: |4
            actions: "enqueue, allocate, preemptpf, backfill"
            tiers:
            - plugins:
              - name: priority
                enableJobOrder: true
              - name: gang
              - name: conformance
            - plugins:
              - name: kmpredicates
                arguments:
                  kmpredicate.GPUTopoEnable: true
                  kmpredicate.AvailableGPUTypes: "baidu.com/gpu_p40_8,baidu.com/v100_cgpu,baidu.com/p40_cgpu"
              - name: proportionpf
                enableJobEnqueued: true
              - name: nodeorder
              - name: binpack
                arguments:
                  binpack.weight: 10
                  binpack.cpu: 3
                  binpack.memory: 1
                  binpack.resources: baidu.com/p40_cgpu, baidu.com/p40_cgpu_core, baidu.com/p40_cgpu_memory, baidu.com/v100_cgpu, baidu.com/v100_cgpu_core, baidu.com/v100_cgpu_memory
                  binpack.resources.baidu.com/v100_cgpu_memory: 6
                  binpack.resources.baidu.com/p40_cgpu: 0
                  binpack.resources.baidu.com/p40_cgpu_core: 0
                  binpack.resources.baidu.com/p40_cgpu_memory: 6
binaryData: {}
---
# Source: pfchart/charts/paddleflow-server/templates/ClusterRole-paddleflow-server.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: paddleflow-server
rules:
- apiGroups:
  - ""
  resources:
  - events
  - pods
  - pods/log
  - services
  - persistentvolumeclaims
  - persistentvolumes
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - '*'
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - '*'
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - sparkoperator.k8s.io
  - batch.paddlepaddle.org
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  - bus.volcano.sh
  - batch.volcano.sh
  - argoproj.io
  - kubeflow.org
  - ray.io
  resources:
  - '*'
  verbs:
  - '*'
---
# Source: pfchart/charts/pfs-csi-plugin/templates/ClusterRole-paddleflow-csi-plugin-clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: paddleflow-csi-plugin-clusterrole
rules:
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - bind
  - delete
  - patch
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - bind
  - patch
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - create
- apiGroups:
  - ""
  resources:
  - nodes/proxy
  verbs:
  - get
  - list
  - watch
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/ClusterRole-external-provisioner-runner.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: external-provisioner-runner
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
  - create
  - delete
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - list
  - watch
  - create
  - update
  - patch
- apiGroups:
  - snapshot.storage.k8s.io
  resources:
  - volumesnapshots
  verbs:
  - get
  - list
- apiGroups:
  - snapshot.storage.k8s.io
  resources:
  - volumesnapshotcontents
  verbs:
  - get
  - list
- apiGroups:
  - storage.k8s.io
  resources:
  - csinodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
---
# Source: pfchart/charts/volcano-admission/templates/ClusterRole-volcano-admission.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: volcano-admission
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - nodes
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - get
  - list
  - watch
  - create
  - update
- apiGroups:
  - certificates.k8s.io
  resources:
  - certificatesigningrequests
  verbs:
  - get
  - list
  - create
  - delete
- apiGroups:
  - certificates.k8s.io
  resources:
  - certificatesigningrequests/approval
  verbs:
  - create
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - create
  - get
  - patch
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - queues
  verbs:
  - get
  - list
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - elasticresourcequotas
  - elasticresourcequotas/status
  verbs:
  - get
  - list
  - update
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - podgroups
  verbs:
  - get
  - list
  - watch
---
# Source: pfchart/charts/volcano-controller/templates/ClusterRole-volcano-controllers.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: volcano-controllers
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - create
  - get
  - list
  - watch
  - delete
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs
  verbs:
  - get
  - list
  - watch
  - update
  - delete
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs/status
  - jobs/finalizers
  verbs:
  - update
  - patch
- apiGroups:
  - bus.volcano.sh
  resources:
  - commands
  verbs:
  - get
  - list
  - watch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - list
  - watch
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - bind
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
- apiGroups:
  - ""
  resources:
  - services
  verbs:
  - get
  - list
  - watch
  - create
  - delete
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - podgroups
  - queues
  - queues/status
  - elasticresourcequotas
  - elasticresourcequotas/status
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
- apiGroups:
  - scheduling.k8s.io
  resources:
  - priorityclasses
  verbs:
  - get
  - list
  - watch
  - create
  - delete
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - get
  - create
  - delete
---
# Source: pfchart/charts/volcano-scheduler/templates/ClusterRole-volcano-scheduler.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: volcano-scheduler
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - create
  - get
  - list
  - watch
  - delete
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs
  verbs:
  - get
  - list
  - watch
  - update
  - delete
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs/status
  verbs:
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - update
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - list
  - watch
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  - pods/status
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - pods/binding
  verbs:
  - create
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - resourcequotas
  verbs:
  - list
  - watch
  - create
  - update
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - scheduling.k8s.io
  resources:
  - priorityclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - queues
  - elasticresourcequotas
  verbs:
  - get
  - list
  - watch
  - create
  - delete
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - podgroups
  verbs:
  - list
  - watch
  - update
---
# Source: pfchart/charts/paddleflow-server/templates/ClusterRoleBinding-paddleflow-server.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: paddleflow-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: paddleflow-server
subjects:
- kind: ServiceAccount
  name: paddleflow-server
  namespace: paddleflow
---
# Source: pfchart/charts/pfs-csi-plugin/templates/ClusterRoleBinding-csi-plugin-clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: csi-plugin-clusterrolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: paddleflow-csi-plugin-clusterrole
subjects:
- kind: ServiceAccount
  name: csi-node-sa
  namespace: paddleflow
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/ClusterRoleBinding-csi-provisioner-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: csi-provisioner-role
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: external-provisioner-runner
subjects:
- kind: ServiceAccount
  name: pfs-csi-provisioner
  namespace: 'paddleflow'
---
# Source: pfchart/charts/volcano-admission/templates/ClusterRoleBinding-volcano-admission-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: volcano-admission-role
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: volcano-admission
subjects:
- kind: ServiceAccount
  name: volcano-admission
  namespace: paddleflow
---
# Source: pfchart/charts/volcano-controller/templates/ClusterRoleBinding-volcano-controllers-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: volcano-controllers-role
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: volcano-controllers
subjects:
- kind: ServiceAccount
  name: volcano-controllers
  namespace: paddleflow
---
# Source: pfchart/charts/volcano-scheduler/templates/ClusterRoleBinding-volcano-scheduler-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: volcano-scheduler-role
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: volcano-scheduler
subjects:
- kind: ServiceAccount
  name: volcano-scheduler
  namespace: paddleflow
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/Role-external-provisioner-cfg.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  creationTimestamp: null
  name: external-provisioner-cfg
  namespace: 'paddleflow'
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  verbs:
  - get
  - watch
  - list
  - delete
  - update
  - create
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - watch
  - list
  - delete
  - update
  - create
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/RoleBinding-csi-provisioner-role-cfg.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  creationTimestamp: null
  name: csi-provisioner-role-cfg
  namespace: 'paddleflow'
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: external-provisioner-cfg
subjects:
- kind: ServiceAccount
  name: pfs-csi-provisioner
  namespace: 'paddleflow'
---
# Source: pfchart/charts/paddleflow-server/templates/paddleflow-server-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: paddleflow-server
  labels:
    app: paddleflow-server
    chart: "paddleflow-server-0.10.57-rq5yqh"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'paddleflow-server-0.10.57-rq5yqh'
    app.kubernetes.io/name: 'paddleflow-server'

  annotations:
spec:
  type: NodePort
  sessionAffinity: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  ports:
  - name: port-0
    port: 8999
    nodePort: 8999
    protocol: TCP
    targetPort: 8999
  selector:
    app: paddleflow-server
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/pfs-csi-provisioner-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pfs-csi-provisioner-service
  labels:
    app: pfs-csi-provisioner
    chart: "pfs-csi-provisioner-0.0.15-rq5zmw"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
    app.kubernetes.io/name: 'pfs-csi-provisioner'

  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  ports:
  - name: port-0
    port: 12345
    protocol: TCP
    targetPort: 12345
  selector:
    app: pfs-csi-provisioner
---
# Source: pfchart/charts/volcano-admission/templates/volcano-admission-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: volcano-admission-service
  labels:
    app: volcano-admission
    chart: "volcano-admission-0.0.21-rq5ysr"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-admission-0.0.21-rq5ysr'
    app.kubernetes.io/name: 'volcano-admission'

  annotations:
spec:
  type: NodePort
  sessionAffinity: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  ports:
  - name: 
    port: 443
    nodePort: 18443
    protocol: TCP
    targetPort: 8443
  selector:
    app: volcano-admission
---
# Source: pfchart/charts/volcano-scheduler/templates/volcano-scheduler-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: volcano-scheduler-service
  labels:
    app: volcano-scheduler
    chart: "volcano-scheduler-0.0.23-rq5ywm"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-scheduler-0.0.23-rq5ywm'
    app.kubernetes.io/name: 'volcano-scheduler'

  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  ports:
  - name: port-0
    port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    app: volcano-scheduler
---
# Source: pfchart/charts/pfs-csi-plugin/templates/pfs-csi-plugin-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  #文件里的所有pfs-csi-plugin、pfs_csi_plugin都替换成实际名称
  name: pfs-csi-plugin
  labels:
    app: pfs-csi-plugin
    chart: "pfs-csi-plugin-0.0.79-rq5znw"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'pfs-csi-plugin-0.0.79-rq5znw'
    app.kubernetes.io/name: 'pfs-csi-plugin'
  annotations:
    reloader.stakater.com/auto: "false"
spec:
  selector:
    matchLabels:
      app: pfs-csi-plugin
  template:
    metadata:
      labels:
        app: pfs-csi-plugin
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'pfs-csi-plugin-0.0.79-rq5znw'
        app.kubernetes.io/name: 'pfs-csi-plugin'
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirstWithHostNet
      restartPolicy: Always
      hostNetwork: true
      serviceAccountName: csi-node-sa
      containers:
      - name: pfs-csi-plugin
        image: "paddleflow/csi-driver-registrar:1.2.0"
        imagePullPolicy: "IfNotPresent"
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - rm -rf /registration/pfs-csi /registration/paddleflowstorage-reg.sock
        args:
        - --v=5
        - --csi-address=/csi/csi.sock
        - --kubelet-registration-path=$(KUBELET_DATA_PATH)/plugins/pfs-csi/csi.sock
        securityContext:
          privileged: true
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟pfs_csi_plugin-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        - name: "KUBE_NODE_NAME"
          valueFrom:
              fieldRef:
                  fieldPath: spec.nodeName
          
        - name: "MOUNT_POINT_INTERVAL_TIME"
          value: "10"
        - name: "KUBELET_DATA_PATH"
          value: "/var/lib/kubelet"
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: socket-dir
          mountPath: /csi
          mountPropagation: None
          subPath: 
        - name: registration-dir
          mountPath: /registration
          mountPropagation: None
          subPath: 

      - name: csi-storage-driver
        image: paddleflow/pfs-csi-plugin:1.4.5.2
        imagePullPolicy: 
        command:
        - /sbin/tini
        - --
        - /bin/sh
        - -c
        - cd /home/paddleflow && /home/paddleflow/csi-plugin --unix-endpoint=$(CSI_ENDPOINT)
          --node-id=$(KUBE_NODE_NAME) --log-dir=./log/csidriver --username=root --password=paddleflow
          --log-level=debug
        securityContext:
          capabilities:
            add:
            - SYS_ADMIN
          privileged: true
          runAsGroup: 0
          runAsUser: 0
        resources:
          limits:
            cpu: "1.5"
            memory: 3000Mi
          requests:
            cpu: "0.5"
            memory: 1000Mi
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #env_list
        - name: "CSI_ENDPOINT"
          value: "unix:///csi/csi.sock"
        - name: "DEFAULT_GID_ENV"
          value: "601"
        - name: "DEFAULT_UID_ENV"
          value: "601"
        - name: "KUBELET_DATA_PATH"
          value: "/var/lib/kubelet"
        - name: "CSI_NAMESPACE"
          valueFrom:
              fieldRef:
                  fieldPath: metadata.namespace
          
        - name: "CSI_POD_NAME"
          valueFrom:
              fieldRef:
                  fieldPath: metadata.name
          
        - name: "KUBE_NODE_NAME"
          valueFrom:
              fieldRef:
                  fieldPath: spec.nodeName
        #env end
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: socket-dir
          mountPath: /csi
          mountPropagation: None
          subPath: 
        - name: mountpoint-dir
          mountPath: /var/lib/kubelet/pods
          mountPropagation: Bidirectional
          subPath: 
        - name: plugins-dir
          mountPath: /var/lib/kubelet/plugins
          mountPropagation: Bidirectional
          subPath: 
        - name: paddlefow-csi-log
          mountPath: /home/paddleflow/log
          mountPropagation: None
          subPath: 
        - name: pfs-mnt
          mountPath: /home/paddleflow/mnt
          mountPropagation: Bidirectional
          subPath: 

  #sidecar container messages
      initContainers:
      volumes:
      - name: fuse
        hostPath: 
          path: /dev/fuse
          type: File
      - name: mountpoint-dir
        hostPath: 
          path: /var/lib/kubelet/pods
          type: DirectoryOrCreate
      - name: paddlefow-csi-log
        hostPath: 
          path: /home/paddleflow/log
          type: DirectoryOrCreate
      - name: pfs-mnt
        hostPath: 
          path: /var/lib/kubelet/data/paddleflow-fs/mnt
          type: DirectoryOrCreate
      - name: plugins-dir
        hostPath: 
          path: /var/lib/kubelet/plugins
          type: DirectoryOrCreate
      - name: registration-dir
        hostPath: 
          path: /var/lib/kubelet/plugins_registry
          type: DirectoryOrCreate
      - name: socket-dir
        hostPath: 
          path: /var/lib/kubelet/plugins/pfs-csi
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
---
# Source: pfchart/charts/paddleflow-server/templates/paddleflow-server-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #文件里的所有paddleflow-server、paddleflow_server都替换成实际名称
  name: paddleflow-server
  labels:
    app: paddleflow-server
    chart: "paddleflow-server-0.10.57-rq5yqh"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'paddleflow-server-0.10.57-rq5yqh'
    app.kubernetes.io/name: 'paddleflow-server'
  annotations:
    reloader.stakater.com/auto: "false"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: paddleflow-server
  template:
    metadata:
      labels:
        app: paddleflow-server
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'paddleflow-server-0.10.57-rq5yqh'
        app.kubernetes.io/name: 'paddleflow-server'
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      securityContext:
        runAsGroup: 1000
        runAsUser: 1000
      serviceAccountName: paddleflow-server
      containers:
      - name: paddleflow-server
        image: "paddleflow/paddleflow-server:1.4.5.2"
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/sh
        args:
        #container_args list
          - -c
          - cd /home/paddleflow/server && ./paddleflow   --mount-pod-expire=2m
        securityContext:
          privileged: false
          runAsGroup: 1000
          runAsUser: 1000
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟paddleflow_server-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        - name: "KUBE_NODE_NAME"
          valueFrom:
              fieldRef:
                  fieldPath: spec.nodeName
          
        - name: "PF_RUNTIME_VERSION"
          value: "v2"
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: conf
          #容器里配置文件存放路径
          mountPath: /home/paddleflow/server/config/server/default/paddleserver.yaml
          #容器里配置文件名称
          subPath: paddleserver.yaml
        - name: conf
          #容器里配置文件存放路径
          mountPath: /home/paddleflow/server/config/fs/default_pvc.yaml
          #容器里配置文件名称
          subPath: default_pvc.yaml
        - name: conf
          #容器里配置文件存放路径
          mountPath: /home/paddleflow/server/config/fs/default_pv.yaml
          #容器里配置文件名称
          subPath: default_pv.yaml
        - name: conf
          #容器里配置文件存放路径
          mountPath: /home/paddleflow/server/config/server/default/job/job_template.yaml
          #容器里配置文件名称
          subPath: job_template.yaml
      initContainers:
      volumes:
      - name: paddleflowdir
        hostPath: 
          path: /mnt/paddleflow
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
      - name: conf
        configMap:
          name: paddleflow-server
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/pfs-csi-provisioner-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #文件里的所有pfs-csi-provisioner、pfs_csi_provisioner都替换成实际名称
  name: pfs-csi-provisioner
  labels:
    app: pfs-csi-provisioner
    chart: "pfs-csi-provisioner-0.0.15-rq5zmw"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
    app.kubernetes.io/name: 'pfs-csi-provisioner'
    app: pfs-csi-provisioner
  annotations:
    app: pfs-csi-provisioner
    reloader.stakater.com/auto: "false"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pfs-csi-provisioner
  template:
    metadata:
      labels:
        app: pfs-csi-provisioner
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'pfs-csi-provisioner-0.0.15-rq5zmw'
        app.kubernetes.io/name: 'pfs-csi-provisioner'
        app: pfs-csi-provisioner
      annotations:
        app: pfs-csi-provisioner
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists

      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - pfs-csi-plugin
            topologyKey: kubernetes.io/hostname
      serviceAccountName: pfs-csi-provisioner
      containers:
      - name: pfs-csi-provisioner
        image: "paddleflow/csi-provisioner:1.4.0"
        imagePullPolicy: "IfNotPresent"
        args:
        #container_args list
          - -v=5
          - --csi-address=/csi/csi.sock
          - --feature-gates=Topology=true
        securityContext:
          privileged: true
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟pfs_csi_provisioner-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: socket-dir
          mountPath: /csi
          mountPropagation: None
          subPath: 
      initContainers:
      volumes:
      - name: socket-dir
        hostPath: 
          path: /var/lib/kubelet/plugins/pfs-csi
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
---
# Source: pfchart/charts/volcano-admission/templates/volcano-admission-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #文件里的所有volcano-admission、volcano_admission都替换成实际名称
  name: volcano-admission
  labels:
    app: volcano-admission
    chart: "volcano-admission-0.0.21-rq5ysr"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-admission-0.0.21-rq5ysr'
    app.kubernetes.io/name: 'volcano-admission'
    app: volcano-admission
  annotations:
    app: volcano-admission
    reloader.stakater.com/auto: "false"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: volcano-admission
  template:
    metadata:
      labels:
        app: volcano-admission
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'volcano-admission-0.0.21-rq5ysr'
        app.kubernetes.io/name: 'volcano-admission'
        app: volcano-admission
      annotations:
        app: volcano-admission
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      serviceAccountName: volcano-admission
      containers:
      - name: volcano-admission
        image: "paddleflow/vc-webhook-manager:pf1.4-vc1.3-rc1"
        imagePullPolicy: "IfNotPresent"
        args:
        #container_args list
          - --tls-cert-file=/admission.local.config/certificates/tls.crt
          - --tls-private-key-file=/admission.local.config/certificates/tls.key
          - --ca-cert-file=/admission.local.config/certificates/ca.crt
          - --webhook-namespace=volcano-system
          - --webhook-service-name=volcano-admission-service
          - --logtostderr=false
          - --port=8443
          - -v=4
          - 2>&1
          - --alsologtostderr
          - --log_dir=/tmp/log
          - --log_file=/tmp/log/webhook.log
          - --log_file_max_size=300
          - --nvidia-mps-dev-volume-host-path=/dev/shm
          - --nvidia-mps-dev-volume-container-path=/dev/shm
          - --nvidia-cgpu-volume-host-path=/baidu-cgpu
          - --nvidia-cgpu-volume-container-path=/home/baidu-cgpu
          - --nvidia-lib-cuda-volume-host-path=/opt/baidu-cgpu/lib64/libcuda.so.1
          - --nvidia-lib-cuda-volume-centos-container-path=/usr/lib64/libcuda.so.1
          - --nvidia-lib-cuda-volume-ubuntu-container-path=/usr/lib/x86_64-linux-gnu/libcuda.so.1
          - --nvidia-lib-cuda-original-volume-host-path=/usr/lib64/libcuda.so.1
          - --nvidia-lib-cuda-original-volume-container-path=/usr/lib64/libcuda_original.so
          - --nvidia-libml-volume-host-path=/opt/baidu-cgpu/lib64/libnvidia-ml.so.1
          - --nvidia-libml-volume-centos-container-path=/usr/lib64/libnvidia-ml.so.1
          - --nvidia-libml-volume-ubuntu-container-path=/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1
          - --nvidia-libml-original-volume-host-path=/usr/lib64/libnvidia-ml.so
          - --nvidia-libml-original-volume-container-path=/usr/lib64/libnvidia-ml_original.so
        securityContext:
          privileged: false
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟volcano_admission-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: logdir
          mountPath: /tmp/log
          mountPropagation: None
          subPath: 
        - name: volcano-admission-secret
          #容器里配置文件存放路径
          mountPath: /admission.local.config/certificates
          #容器里配置文件名称
          subPath: 
      initContainers:
      volumes:
      - name: logdir
        hostPath: 
          path: /mnt/log/volcano/admission
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
      - name: volcano-admission-secret
        secret:
          secretName: volcano-admission-secret
---
# Source: pfchart/charts/volcano-controller/templates/volcano-controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #文件里的所有volcano-controller、volcano_controller都替换成实际名称
  name: volcano-controller
  labels:
    app: volcano-controller
    chart: "volcano-controller-0.0.11-rq5yy7"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-controller-0.0.11-rq5yy7'
    app.kubernetes.io/name: 'volcano-controller'
    app: volcano-controller
  annotations:
    app: volcano-controller
    reloader.stakater.com/auto: "false"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: volcano-controller
  template:
    metadata:
      labels:
        app: volcano-controller
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'volcano-controller-0.0.11-rq5yy7'
        app.kubernetes.io/name: 'volcano-controller'
        app: volcano-controller
      annotations:
        app: volcano-controller
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      serviceAccountName: volcano-controllers
      containers:
      - name: volcano-controller
        image: "paddleflow/vc-controller-manager:pf1.4-vc1.3-rc1"
        imagePullPolicy: "IfNotPresent"
        args:
        #container_args list
          - --logtostderr=false
          - -v=4
          - 2>&1
          - --log_dir=/tmp/log
          - --alsologtostderr
          - --log_file=/tmp/log/controller.log
          - --log_file_max_size=300
        securityContext:
          privileged: false
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟volcano_controller-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: logdir
          mountPath: /tmp/log
          mountPropagation: None
          subPath: 
      initContainers:
      volumes:
      - name: logdir
        hostPath: 
          path: /mnt/log/volcano/controller
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
---
# Source: pfchart/charts/volcano-scheduler/templates/volcano-scheduler-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  #文件里的所有volcano-scheduler、volcano_scheduler都替换成实际名称
  name: volcano-scheduler
  labels:
    app: volcano-scheduler
    chart: "volcano-scheduler-0.0.23-rq5ywm"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-scheduler-0.0.23-rq5ywm'
    app.kubernetes.io/name: 'volcano-scheduler'
    app: volcano-scheduler
  annotations:
    app: volcano-scheduler
    reloader.stakater.com/auto: "false"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: volcano-scheduler
  template:
    metadata:
      labels:
        app: volcano-scheduler
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'volcano-scheduler-0.0.23-rq5ywm'
        app.kubernetes.io/name: 'volcano-scheduler'
        app: volcano-scheduler
      annotations:
        app: volcano-scheduler
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      serviceAccountName: volcano-scheduler
      containers:
      - name: volcano-scheduler
        image: "paddleflow/vc-scheduler:pf1.4-vc1.3-rc1"
        imagePullPolicy: "IfNotPresent"
        args:
        #container_args list
          - --alsologtostderr
          - --scheduler-conf=/volcano.scheduler/volcano-scheduler-pf.conf
          - -v=4
          - 2>&1
          - --scheduler-name=volcano
          - --log_dir=/tmp/log
          - --logtostderr=false
          - --log_file_max_size=100
          - --log_file=/tmp/log/scheduler.log
        securityContext:
          privileged: false
        #服务启动暴露的端口，list形式，根据服务情况增加或删减
        #注意：这个要跟volcano_scheduler-service.yaml里的ports一一对应
        ports:
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
        - name: scheduler-logdir
          mountPath: /tmp/log
          mountPropagation: None
          subPath: 
        - name: conf
          #容器里配置文件存放路径
          mountPath: /volcano.scheduler/volcano-scheduler-pf.conf
          #容器里配置文件名称
          subPath: volcano-scheduler-pf.conf
      initContainers:
      volumes:
      - name: scheduler-logdir
        hostPath: 
          path: /mnt/log/volcano/scheduler
          type: DirectoryOrCreate
      # 集群已存在的configMap和secret
      - name: conf
        configMap:
          name: volcano-scheduler
---
# Source: pfchart/charts/volcano-admission-init/templates/volcano-admission-init-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  #文件里的所有volcano-admission-init、volcano_admission_init都替换成实际名称
  name: volcano-admission-init
  labels:
    app: volcano-admission-init
    chart: "volcano-admission-init-0.0.8-rq5yzc"
    release: "paddleflow"
    heritage: "Helm"
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/instance: 'paddleflow'
    helm.sh/chart: 'volcano-admission-init-0.0.8-rq5yzc'
    app.kubernetes.io/name: 'volcano-admission-init'
    app: volcano-admission-init
  annotations:
    reloader.stakater.com/auto: "false"
spec:
  backoffLimit: 3
  completions: 1
  parallelism: 1
  activeDeadlineSeconds: 120
  ttlSecondsAfterFinished: 100
  template:
    metadata:
      labels:
        app.kubernetes.io/managed-by: 'Helm'
        app.kubernetes.io/instance: 'paddleflow'
        helm.sh/chart: 'volcano-admission-init-0.0.8-rq5yzc'
        app.kubernetes.io/name: 'volcano-admission-init'
    spec:
      imagePullSecrets:
      - name: registry-paddleflow
      serviceAccountName: volcano-admission
      containers:
      - name: volcano-admission-init
        image: "paddleflow/vc-webhook-manager:pf1.4-vc1.3-rc1"
        imagePullPolicy: "IfNotPresent"
        command:
        - ./gen-admission-secret.sh
        - --service
        - volcano-admission-service
        - --namespace
        - volcano-system
        - --secret
        - volcano-admission-secret
        securityContext:
          privileged: false
        #服务的环境变量，list形式，根据服务情况增加或删减
        env:
        #container_envs list
        #注意：这里的name跟后面volumes里name是一一对应的
        volumeMounts:
      initContainers:
      volumes:
      # 集群已存在的configMap和secret
      restartPolicy: OnFailure
---
# Source: pfchart/charts/pfs-csi-provisioner/templates/paddleflowstorage.yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
    name: paddleflowstorage
spec:
    attachRequired: false
    podInfoOnMount: false
    volumeLifecycleModes:
        - Persistent
---
# Source: pfchart/charts/volcano-scheduler/templates/high.yaml
apiVersion: scheduling.k8s.io/v1
description: Used for critical pods that must not be moved from their current node.
kind: PriorityClass
metadata:
    name: high
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/high
value: 1000
---
# Source: pfchart/charts/volcano-scheduler/templates/low.yaml
apiVersion: scheduling.k8s.io/v1
description: Used for low-priority Pods that are easily preempted.
kind: PriorityClass
metadata:
    name: low
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/low
value: 50
---
# Source: pfchart/charts/volcano-scheduler/templates/normal.yaml
apiVersion: scheduling.k8s.io/v1
description: Used for normal pods.
globalDefault: true
kind: PriorityClass
metadata:
    name: normal
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/normal
value: 100
---
# Source: pfchart/charts/volcano-scheduler/templates/very-high.yaml
apiVersion: scheduling.k8s.io/v1
description: Used for system critical pods that must not be moved from their current node.
kind: PriorityClass
metadata:
    name: very-high
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/very-high
value: 2000
---
# Source: pfchart/charts/volcano-scheduler/templates/very-low.yaml
apiVersion: scheduling.k8s.io/v1
description: Used for pods that are easily preempted and unimportant.
kind: PriorityClass
metadata:
    name: very-low
    selfLink: /apis/scheduling.k8s.io/v1/priorityclasses/very-low
value: 10